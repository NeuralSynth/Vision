# ğŸ“± Vision Assistance App

## ğŸ“ Overview
The **Vision Assistance App** is designed to help individuals who are completely or heavily partially blind navigate the real world independently. It utilizes AI-powered object detection, haptic feedback, and emergency features to enhance accessibility and safety.

## âœ¨ Features

### ğŸ” Object Detection & Distance Feedback
- Uses the mobile deviceâ€™s camera to detect objects in real-time.
- Divides the field of view into **9 quadrants (3x3 grid)** to indicate object location.
- Estimates object distance using **vibration motors** (intensity-based feedback).
- Provides **haptic feedback** for better interaction.
- Recognizes **household items and human faces** accurately.

### ğŸ›ï¸ Interactive Buttons & Controls
- **9 on-screen buttons** mapped to the 9 quadrants:
  1. ğŸ“ **Describe Object in Detail** â€“ Short description first, detailed info on press.
  2. ğŸ“ **Call Emergency Contact** â€“ Quick dial to a preset number (family, caretaker, etc.).
  3-9. ğŸ›ï¸ Additional customizable buttons for:
     - **Voice commands** ğŸ™ï¸.
     - **Saving object details** for later reference.
     - **Adjusting vibration intensity** âš™ï¸.
     - **Toggling features on/off** ğŸ“´.
- **Physical button shortcuts** using volume and power button combinations.

### ğŸš¨ Accident Detection & Emergency Alerts
- **GPS functionality** for navigation and location tracking.
- **Fall detection** that automatically sends emergency alerts ğŸ“¡.
- **Health info storage** at startup for medical emergencies ğŸ¥.
- **Auto emergency message** ğŸ“© with location and medical info sent to hospitals and family members.

### ğŸ”§ Additional Features
- **Voice assistance** ğŸ™ï¸ for optional audio cues.
- **Configurable grid system** (3x3 or 2x4) ğŸ“ for different navigation needs.
- **AI-powered object recognition** ğŸ¤– for improved accuracy.
- **Offline functionality** âš¡ for essential features.
- **Customizable vibration patterns** for different object types.

## ğŸš€ How It Works
1. Open the app ğŸ“².
2. Point the camera at your surroundings ğŸ¥.
3. Receive **real-time object detection feedback** with vibration and haptic cues ğŸ“³.
4. Use on-screen buttons for additional assistance ğŸ›ï¸.
5. Enable **GPS navigation** or **fall detection alerts** for added safety ğŸ—ºï¸.

## ğŸ› ï¸ Tech Stack
- **Language:** Java/Kotlin (Android) or Swift (iOS)
- **Machine Learning:** TensorFlow Lite / OpenCV
- **Haptic Feedback:** Android Vibration API, iOS Core Haptics
- **GPS & Emergency Alerts:** Google Maps API, Twilio API

## ğŸ“Œ Future Enhancements
- ğŸŒ Multi-language support.
- ğŸµ Dynamic sound cues for navigation.
- ğŸ¦¾ Integration with smart wearables (e.g., neosapien).
- ğŸ—‚ï¸ Cloud-based object recognition for improved AI training.

## ğŸ—ï¸ Installation & Setup
1. Clone the repo:
   ```bash
   git clone https://github.com/yourusername/Vision-Assistance-App.git
   ```
2. Open the project in Android Studio/Xcode.
3. Build and install on a test device.

## ğŸ“œ License
This project is licensed under the **MIT License**.

---
ğŸ‘¨â€ğŸ’» **Contributions are welcome!** Open an issue or create a pull request to suggest improvements. ğŸš€

